{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/qlib/blob/main/examples/workflow_by_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow of Qlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import sys\n",
    "import qlib\n",
    "from qlib.config import REG_CN\n",
    "from qlib.utils import init_instance_by_config\n",
    "from qlib.workflow import R\n",
    "from qlib.workflow.record_temp import SignalRecord, SigAnaRecord, PortAnaRecord\n",
    "from qlib.contrib.model.pytorch_master_ts import MASTERModel\n",
    "from qlib.contrib.data.dataset import MASTERTSDatasetH\n",
    "from qlib.contrib.data.handler import Alpha158"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Qlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-07 00:07:38.867\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mqlib.tests.data\u001b[0m:\u001b[36mqlib_data\u001b[0m:\u001b[36m195\u001b[0m - \u001b[33m\u001b[1mData already exists: ~/QuantProject/.qlib/qlib_data/cn_data, the data download will be skipped\n",
      "\tIf downloading is required: `exists_skip=False` or `change target_dir`\u001b[0m\n",
      "[3908378:MainThread](2025-04-07 00:07:38,874) INFO - qlib.Initialization - [config.py:420] - default_conf: client.\n",
      "[3908378:MainThread](2025-04-07 00:07:38,879) INFO - qlib.Initialization - [__init__.py:74] - qlib successfully initialized based on client settings.\n",
      "[3908378:MainThread](2025-04-07 00:07:38,880) INFO - qlib.Initialization - [__init__.py:76] - data_path={'__DEFAULT_FREQ': PosixPath('/home/24039378g/QuantProject/.qlib/qlib_data/cn_data')}\n"
     ]
    }
   ],
   "source": [
    "from qlib.tests.data import GetData\n",
    "\n",
    "\n",
    "provider_uri = \"~/QuantProject/.qlib/qlib_data/cn_data\"\n",
    "GetData().qlib_data(target_dir=provider_uri, region=REG_CN, exists_skip=True)\n",
    "qlib.init(provider_uri=provider_uri, region=REG_CN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration of Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置参数\n",
    "market = \"csi300\"\n",
    "benchmark = \"SH000300\"\n",
    "\n",
    "# 数据处理器配置\n",
    "data_handler_config = {\n",
    "    \"start_time\": \"2008-01-01\",\n",
    "    \"end_time\": \"2020-08-01\",\n",
    "    \"fit_start_time\": \"2008-01-01\",\n",
    "    \"fit_end_time\": \"2014-12-31\",\n",
    "    \"instruments\": market,\n",
    "    \"infer_processors\": [\n",
    "        {\n",
    "            \"class\": \"RobustZScoreNorm\",\n",
    "            \"kwargs\": {\n",
    "                \"fields_group\": \"feature\",\n",
    "                \"clip_outlier\": True\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"class\": \"Fillna\",\n",
    "            \"kwargs\": {\n",
    "                \"fields_group\": \"feature\"\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"learn_processors\": [\n",
    "        {\"class\": \"DropnaLabel\"},\n",
    "        {\n",
    "            \"class\": \"CSRankNorm\",\n",
    "            \"kwargs\": {\n",
    "                \"fields_group\": \"label\"\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"label\": [\"Ref($close, -5) / Ref($close, -1) - 1\"]\n",
    "}\n",
    "\n",
    "market_data_handler_config = {\n",
    "    \"start_time\": \"2008-01-01\",\n",
    "    \"end_time\": \"2020-08-01\",\n",
    "    \"fit_start_time\": \"2008-01-01\",\n",
    "    \"fit_end_time\": \"2014-12-31\",\n",
    "    \"instruments\": market,\n",
    "    \"infer_processors\": [\n",
    "        {\n",
    "            \"class\": \"RobustZScoreNorm\",\n",
    "            \"kwargs\": {\n",
    "                \"fields_group\": \"feature\",\n",
    "                \"clip_outlier\": True\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"class\": \"Fillna\",\n",
    "            \"kwargs\": {\n",
    "                \"fields_group\": \"feature\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 模型配置\n",
    "model_config = {\n",
    "    \"class\": \"MASTERModel\",\n",
    "    \"module_path\": \"qlib.contrib.model.pytorch_master_ts\",\n",
    "    \"kwargs\": {\n",
    "        \"seed\": 0,\n",
    "        \"n_epochs\": 1,\n",
    "        \"lr\": 0.000008,\n",
    "        \"train_stop_loss_thred\": 0.95,\n",
    "        \"market\": market,\n",
    "        \"benchmark\": benchmark,\n",
    "        \"save_prefix\": market\n",
    "    }\n",
    "}\n",
    "\n",
    "# 数据集配置\n",
    "dataset_config = {\n",
    "    \"class\": \"MASTERTSDatasetH\",\n",
    "    \"module_path\": \"qlib.contrib.data.dataset\",\n",
    "    \"kwargs\": {\n",
    "        \"handler\": {\n",
    "            \"class\": \"Alpha158\",\n",
    "            \"module_path\": \"qlib.contrib.data.handler\",\n",
    "            \"kwargs\": data_handler_config\n",
    "        },\n",
    "        \"segments\": {\n",
    "            \"train\": [\"2008-01-01\", \"2014-12-31\"],\n",
    "            \"valid\": [\"2015-01-01\", \"2016-12-31\"],\n",
    "            \"test\": [\"2017-01-01\", \"2020-08-01\"]\n",
    "        },\n",
    "        \"step_len\": 8,\n",
    "        \"market_data_handler_config\": market_data_handler_config\n",
    "    }\n",
    "}\n",
    "\n",
    "# 投资组合分析配置\n",
    "port_analysis_config = {\n",
    "    \"strategy\": {\n",
    "        \"class\": \"TopkDropoutStrategy\",\n",
    "        \"module_path\": \"qlib.contrib.strategy\",\n",
    "        \"kwargs\": {\n",
    "            \"signal\": \"<PRED>\",\n",
    "            \"topk\": 30,\n",
    "            \"n_drop\": 30\n",
    "        }\n",
    "    },\n",
    "    \"backtest\": {\n",
    "        \"start_time\": \"2017-01-01\",\n",
    "        \"end_time\": \"2020-08-01\",\n",
    "        \"account\": 100000000,\n",
    "        \"benchmark\": benchmark,\n",
    "        \"exchange_kwargs\": {\n",
    "            \"deal_price\": \"close\"\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model and Dataset Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "模型参数量统计:\n",
      "--------------------------------------------------\n",
      "特征门控层 (Gate): 10,112 参数\n",
      "输入映射层 (x2y): 40,704 参数\n",
      "时间注意力层 (TAttention): 329,216 参数\n",
      "空间注意力层 (SAttention): 329,216 参数\n",
      "时序注意力层 (TemporalAttention): 65,536 参数\n",
      "解码器 (Decoder): 257 参数\n",
      "--------------------------------------------------\n",
      "总参数量: 775,041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3908378:MainThread](2025-04-07 00:08:00,546) INFO - qlib.timer - [log.py:127] - Time cost: 11.463s | Loading data Done\n",
      "/home/24039378g/.conda/envs/MASTER/lib/python3.12/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n",
      "[3908378:MainThread](2025-04-07 00:08:05,505) INFO - qlib.timer - [log.py:127] - Time cost: 4.480s | RobustZScoreNorm Done\n",
      "[3908378:MainThread](2025-04-07 00:08:06,106) INFO - qlib.timer - [log.py:127] - Time cost: 0.600s | Fillna Done\n",
      "[3908378:MainThread](2025-04-07 00:08:06,502) INFO - qlib.timer - [log.py:127] - Time cost: 0.217s | DropnaLabel Done\n",
      "/home/24039378g/QuantProject/QLIB/qlib/data/dataset/processor.py:370: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[cols] = t\n",
      "[3908378:MainThread](2025-04-07 00:08:06,724) INFO - qlib.timer - [log.py:127] - Time cost: 0.220s | CSRankNorm Done\n",
      "[3908378:MainThread](2025-04-07 00:08:06,726) INFO - qlib.timer - [log.py:127] - Time cost: 6.179s | fit & process data Done\n",
      "[3908378:MainThread](2025-04-07 00:08:06,727) INFO - qlib.timer - [log.py:127] - Time cost: 17.645s | Init data Done\n",
      "[3908378:MainThread](2025-04-07 00:08:12,237) INFO - qlib.timer - [log.py:127] - Time cost: 5.493s | Loading data Done\n",
      "[3908378:MainThread](2025-04-07 00:08:13,499) INFO - qlib.timer - [log.py:127] - Time cost: 1.196s | RobustZScoreNorm Done\n",
      "[3908378:MainThread](2025-04-07 00:08:13,668) INFO - qlib.timer - [log.py:127] - Time cost: 0.168s | Fillna Done\n",
      "[3908378:MainThread](2025-04-07 00:08:13,674) INFO - qlib.timer - [log.py:127] - Time cost: 1.436s | fit & process data Done\n",
      "[3908378:MainThread](2025-04-07 00:08:13,676) INFO - qlib.timer - [log.py:127] - Time cost: 6.933s | Init data Done\n"
     ]
    }
   ],
   "source": [
    "model = init_instance_by_config(model_config)\n",
    "dataset = init_instance_by_config(dataset_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading or Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3908378:MainThread](2025-04-07 00:09:05,376) INFO - qlib.workflow - [exp.py:258] - Experiment 566184983307789232 starts running ...\n",
      "[3908378:MainThread](2025-04-07 00:09:05,434) INFO - qlib.workflow - [recorder.py:345] - Recorder 11c2d47286df4a929bdb1648d74150ed starts running under Experiment 566184983307789232 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3908378:MainThread](2025-04-07 00:09:05,521) INFO - qlib.timer - [log.py:127] - Time cost: 0.004s | waiting `async_log` Done\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Model not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnpicklingError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/QuantProject/QLIB/qlib/contrib/model/pytorch_master_ts.py:582\u001b[39m, in \u001b[36mMASTERModel.load_model\u001b[39m\u001b[34m(self, param_path)\u001b[39m\n\u001b[32m    581\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m582\u001b[39m     \u001b[38;5;28mself\u001b[39m.model.load_state_dict(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    583\u001b[39m     \u001b[38;5;28mself\u001b[39m.fitted = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/MASTER/lib/python3.12/site-packages/torch/serialization.py:1494\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1493\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1494\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1495\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(\n\u001b[32m   1496\u001b[39m     opened_file, map_location, pickle_module, **pickle_load_args\n\u001b[32m   1497\u001b[39m )\n",
      "\u001b[31mUnpicklingError\u001b[39m: Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\nPlease file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Unsupported operand 149\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m     R.save_objects(trained_model=model)\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./model/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     R.save_objects(trained_model=model)\n\u001b[32m     38\u001b[39m rid = R.get_recorder().id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/QuantProject/QLIB/qlib/contrib/model/pytorch_master_ts.py:585\u001b[39m, in \u001b[36mMASTERModel.load_model\u001b[39m\u001b[34m(self, param_path)\u001b[39m\n\u001b[32m    583\u001b[39m     \u001b[38;5;28mself\u001b[39m.fitted = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    584\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m585\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mModel not found.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Model not found."
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_name = f\"{market}-{model_config[\"class\"]}-model\"\n",
    "model_file_path = Path(f\"./model/{model_name}.pkl\")\n",
    "\n",
    "if not os.path.exists('./model'):\n",
    "    os.makedirs('./model')\n",
    "    \n",
    "with R.start(experiment_name=\"train_model\"):\n",
    "    if not model_file_path.exists():\n",
    "        R.log_params(**model_config[\"kwargs\"])\n",
    "        # print(\"文件列表:\", list(R.get_recorder().list_artifacts()))\n",
    "        \n",
    "        # 方法1：使用 sys.stdout.write\n",
    "        def custom_print(*args, **kwargs):\n",
    "            msg = ' '.join(map(str, args)) + '\\n'\n",
    "            import sys\n",
    "            sys.stdout.write(msg)\n",
    "        \n",
    "        # 临时替换 print\n",
    "        import builtins\n",
    "        orig_print = builtins.print\n",
    "        builtins.print = custom_print\n",
    "        \n",
    "        try:\n",
    "            model.fit(dataset)  # 训练模型\n",
    "        finally:\n",
    "            pkl_path = os.path.join(\"./model\", f\"{model_name}.pkl\")\n",
    "            with open(pkl_path, \"wb\") as f:\n",
    "                pickle.dump(model, f)\n",
    "            builtins.print = orig_print  # 确保恢复原始 print\n",
    "        \n",
    "        R.save_objects(trained_model=model)\n",
    "        \n",
    "    else:\n",
    "        model.load_model(f\"./model/{model_name}.pkl\")\n",
    "        R.save_objects(trained_model=model)\n",
    "        \n",
    "    rid = R.get_recorder().id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = {\n",
    "    k: []\n",
    "    for k in [\n",
    "        \"IC\",\n",
    "        \"ICIR\",\n",
    "        \"Rank IC\",\n",
    "        \"Rank ICIR\",\n",
    "        \"1day.excess_return_without_cost.annualized_return\",\n",
    "        \"1day.excess_return_without_cost.information_ratio\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3908378:MainThread](2025-04-06 22:25:07,912) INFO - qlib.workflow - [exp.py:258] - Experiment 362767161650010529 starts running ...\n",
      "[3908378:MainThread](2025-04-06 22:25:07,977) INFO - qlib.workflow - [recorder.py:345] - Recorder 8d84fab322dd47c782da32d0322d5857 starts running under Experiment 362767161650010529 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS]: MODEL TRAINING/ LOADING FINISHED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3908378:MainThread](2025-04-06 22:25:23,084) INFO - qlib.workflow - [record_temp.py:198] - Signal record 'pred.pkl' has been saved as the artifact of the Experiment 362767161650010529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'The following are prediction results of the MASTERModel model.'\n",
      "                              0\n",
      "datetime   instrument          \n",
      "2017-01-03 SH600000   -0.094200\n",
      "           SH600008    0.099505\n",
      "           SH600009    0.298842\n",
      "           SH600010   -0.023810\n",
      "           SH600015    0.067495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3908378:MainThread](2025-04-06 22:25:23,819) INFO - qlib.backtest caller - [__init__.py:93] - Create new exchange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'IC': 0.03648069232457443,\n",
      " 'ICIR': 0.2675256965377252,\n",
      " 'Rank IC': 0.04273447517543348,\n",
      " 'Rank ICIR': 0.29957152985370383}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3908378:MainThread](2025-04-06 22:25:29,059) WARNING - qlib.online operator - [exchange.py:219] - $close field data contains nan.\n",
      "[3908378:MainThread](2025-04-06 22:25:29,062) WARNING - qlib.online operator - [exchange.py:219] - $close field data contains nan.\n",
      "[3908378:MainThread](2025-04-06 22:25:29,069) WARNING - qlib.online operator - [exchange.py:226] - factor.day.bin file not exists or factor contains `nan`. Order using adjusted_price.\n",
      "[3908378:MainThread](2025-04-06 22:25:29,070) WARNING - qlib.online operator - [exchange.py:228] - trade unit 100 is not supported in adjusted_price mode.\n",
      "[3908378:MainThread](2025-04-06 22:25:44,801) WARNING - qlib.BaseExecutor - [executor.py:121] - `common_infra` is not set for <qlib.backtest.executor.SimulatorExecutor object at 0x1552fea3aea0>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533ff142c9b643d9a444b2869b81b477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "backtest loop:   0%|          | 0/871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/24039378g/QuantProject/QLIB/qlib/utils/index_data.py:492: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(self.data)\n",
      "/home/24039378g/QuantProject/QLIB/qlib/utils/index_data.py:492: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(self.data)\n",
      "/home/24039378g/QuantProject/QLIB/qlib/utils/index_data.py:492: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(self.data)\n",
      "[3908378:MainThread](2025-04-06 22:25:59,916) INFO - qlib.workflow - [record_temp.py:515] - Portfolio analysis record 'port_analysis_1day.pkl' has been saved as the artifact of the Experiment 362767161650010529\n",
      "[3908378:MainThread](2025-04-06 22:25:59,922) INFO - qlib.workflow - [record_temp.py:540] - Indicator analysis record 'indicator_analysis_1day.pkl' has been saved as the artifact of the Experiment 362767161650010529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'The following are analysis results of benchmark return(1day).'\n",
      "                       risk\n",
      "mean               0.000477\n",
      "std                0.012295\n",
      "annualized_return  0.113561\n",
      "information_ratio  0.598699\n",
      "max_drawdown      -0.370479\n",
      "'The following are analysis results of the excess return without cost(1day).'\n",
      "                       risk\n",
      "mean               0.000280\n",
      "std                0.005396\n",
      "annualized_return  0.066689\n",
      "information_ratio  0.801159\n",
      "max_drawdown      -0.119840\n",
      "'The following are analysis results of the excess return with cost(1day).'\n",
      "                       risk\n",
      "mean              -0.001737\n",
      "std                0.005399\n",
      "annualized_return -0.413358\n",
      "information_ratio -4.963131\n",
      "max_drawdown      -1.526544\n",
      "'The following are analysis results of indicators(1day).'\n",
      "     value\n",
      "ffr    1.0\n",
      "pa     0.0\n",
      "pos    0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3908378:MainThread](2025-04-06 22:26:02,053) INFO - qlib.timer - [log.py:127] - Time cost: 0.001s | waiting `async_log` Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: {'1day.ffr': 1.0, 'Rank ICIR': 0.29957152985370383, '1day.excess_return_with_cost.information_ratio': -4.963131106783359, '1day.excess_return_with_cost.annualized_return': -0.4133577531694415, '1day.excess_return_without_cost.information_ratio': 0.8011587221738969, '1day.pos': 0.0, 'IC': 0.03648069232457443, 'ICIR': 0.2675256965377252, '1day.pa': 0.0, '1day.excess_return_without_cost.std': 0.005395668816402809, 'Rank IC': 0.04273447517543348, '1day.excess_return_with_cost.mean': -0.001736797282224544, '1day.excess_return_without_cost.mean': 0.000280204671652662, '1day.excess_return_with_cost.max_drawdown': -1.5265442023044526, '1day.excess_return_without_cost.max_drawdown': -0.11983952371055057, '1day.excess_return_with_cost.std': 0.005398608841853511, '1day.excess_return_without_cost.annualized_return': 0.06668871185333357}\n",
      "All metrics: {'IC': [0.03648069232457443], 'ICIR': [0.2675256965377252], 'Rank IC': [0.04273447517543348], 'Rank ICIR': [0.29957152985370383], '1day.excess_return_without_cost.annualized_return': [0.06668871185333357], '1day.excess_return_without_cost.information_ratio': [0.8011587221738969]}\n",
      "Available metrics: dict_keys(['1day.ffr', 'Rank ICIR', '1day.excess_return_with_cost.information_ratio', '1day.excess_return_with_cost.annualized_return', '1day.excess_return_without_cost.information_ratio', '1day.pos', 'IC', 'ICIR', '1day.pa', '1day.excess_return_without_cost.std', 'Rank IC', '1day.excess_return_with_cost.mean', '1day.excess_return_without_cost.mean', '1day.excess_return_with_cost.max_drawdown', '1day.excess_return_without_cost.max_drawdown', '1day.excess_return_with_cost.std', '1day.excess_return_without_cost.annualized_return'])\n",
      "IC: 0.03648069232457443 +- 0.0\n",
      "ICIR: 0.2675256965377252 +- 0.0\n",
      "Rank IC: 0.04273447517543348 +- 0.0\n",
      "Rank ICIR: 0.29957152985370383 +- 0.0\n",
      "1day.excess_return_without_cost.annualized_return: 0.06668871185333357 +- 0.0\n",
      "1day.excess_return_without_cost.information_ratio: 0.8011587221738969 +- 0.0\n"
     ]
    }
   ],
   "source": [
    "# backtest and analysis\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "print(f\"[Status]: Model Training/ Loading finished\".upper())\n",
    "with R.start(experiment_name=\"backtest_analysis\"):\n",
    "    recorder = R.get_recorder(recorder_id=rid, experiment_name=\"train_model\")\n",
    "    model = recorder.load_object(\"trained_model\")\n",
    "\n",
    "    # prediction\n",
    "    recorder = R.get_recorder()\n",
    "    ba_rid = recorder.id\n",
    "    sr = SignalRecord(model, dataset, recorder)\n",
    "    sr.generate()\n",
    "    \n",
    "    # Signal Analysis\n",
    "    sar = SigAnaRecord(recorder)\n",
    "    sar.generate()\n",
    "\n",
    "    # backtest & analysis\n",
    "    par = PortAnaRecord(recorder, port_analysis_config, \"day\")\n",
    "    par.generate()\n",
    "    \n",
    "    metrics = recorder.list_metrics()\n",
    "    print(f\"Metrics: {metrics}\")\n",
    "    for k in all_metrics.keys():\n",
    "        all_metrics[k].append(metrics[k])\n",
    "    print(f\"All metrics: {all_metrics}\")\n",
    "    print(f\"Available metrics: {metrics.keys()}\")\n",
    "    \n",
    "for k in all_metrics.keys():\n",
    "        print(f\"{k}: {np.mean(all_metrics[k])} +- {np.std(all_metrics[k])}\")\n",
    "\n",
    "recorder = R.get_recorder(recorder_id=ba_rid, experiment_name=\"backtest_analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = recorder.load_object(\"pred.pkl\")\n",
    "\n",
    "report_normal_df = recorder.load_object(\"portfolio_analysis/report_normal_1day.pkl\")\n",
    "\n",
    "positions = recorder.load_object(\"portfolio_analysis/positions_normal_1day.pkl\")\n",
    "\n",
    "analysis_df = recorder.load_object(\"portfolio_analysis/port_analysis_1day.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figure 0 to figure_results/报告图表0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/24039378g/QuantProject/QLIB/qlib/contrib/report/analysis_position/risk_analysis.py:102: FutureWarning:\n",
      "\n",
      "When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "\n",
      "/home/24039378g/QuantProject/QLIB/qlib/contrib/report/analysis_position/risk_analysis.py:102: FutureWarning:\n",
      "\n",
      "When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "\n",
      "/home/24039378g/QuantProject/QLIB/qlib/contrib/report/analysis_position/risk_analysis.py:102: FutureWarning:\n",
      "\n",
      "When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "\n",
      "/home/24039378g/QuantProject/QLIB/qlib/contrib/report/analysis_position/risk_analysis.py:102: FutureWarning:\n",
      "\n",
      "When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figure 0 to figure_results/风险分析图表0.png\n",
      "Saved figure 1 to figure_results/风险分析图表1.png\n",
      "Saved figure 2 to figure_results/风险分析图表2.png\n",
      "Saved figure 3 to figure_results/风险分析图表3.png\n",
      "Saved figure 4 to figure_results/风险分析图表4.png\n",
      "Reshaped label DataFrame:\n",
      "    datetime instrument label\n",
      "0 2016-12-21   SH600000     0\n",
      "1 2016-12-22   SH600000   300\n",
      "2 2016-12-23   SH600000   600\n",
      "3 2016-12-26   SH600000   900\n",
      "4 2016-12-27   SH600000  1200\n",
      "datetime      0\n",
      "instrument    0\n",
      "label         0\n",
      "score         0\n",
      "dtype: int64\n",
      "Saved figure 0 to figure_results/IC图表0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/24039378g/QuantProject/QLIB/qlib/contrib/report/analysis_model/analysis_model_performance.py:155: FutureWarning:\n",
      "\n",
      "'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figure 0 to figure_results/模型性能图表0.png\n",
      "Saved figure 1 to figure_results/模型性能图表1.png\n",
      "Saved figure 2 to figure_results/模型性能图表2.png\n",
      "Saved figure 3 to figure_results/模型性能图表3.png\n",
      "Saved figure 4 to figure_results/模型性能图表4.png\n",
      "Saved figure 5 to figure_results/模型性能图表5.png\n",
      "[STATUS]: MISSION COMPLETED\n"
     ]
    }
   ],
   "source": [
    "from qlib.contrib.report import analysis_model, analysis_position\n",
    "import pandas as pd\n",
    "\n",
    "save_dir = \"figure_results\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "figs = analysis_position.report_graph(report_normal_df, show_notebook=False)\n",
    "if not figs:\n",
    "    raise ValueError(\"No figures were generated by `report_graph`. Please check the input data.\")\n",
    "\n",
    "for i, _fig in enumerate(figs):\n",
    "    fig_path = f\"{save_dir}/报告图表{i}.png\"\n",
    "    try:\n",
    "        _fig.write_image(fig_path)\n",
    "        print(f\"Saved figure {i} to {fig_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving figure {i}: {e}\")\n",
    "\n",
    "figs = analysis_position.risk_analysis_graph(analysis_df, report_normal_df, show_notebook=False)\n",
    "if not figs:\n",
    "    raise ValueError(\"No figures were generated by `risk_analysis_graph`. Please check the input data.\")\n",
    "\n",
    "for i, _fig in enumerate(figs):\n",
    "    fig_path = f\"{save_dir}/风险分析图表{i}.png\"\n",
    "    try:\n",
    "        _fig.write_image(fig_path)\n",
    "        print(f\"Saved figure {i} to {fig_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving figure {i}: {e}\")\n",
    "\n",
    "# Step 1: Retrieve TSDataSampler and extract the underlying DataFrame\n",
    "label_sampler = dataset.prepare(segments=\"test\", col_set=\"label\", only_label=True)\n",
    "label_df = label_sampler.idx_df  # Extract the DataFrame\n",
    "\n",
    "# Step 2: Reshape label_df to long format\n",
    "label_df = label_df.reset_index()  # Include datetime as a column\n",
    "label_df_long = pd.melt(\n",
    "    label_df,\n",
    "    id_vars=[\"datetime\"],  # Keep datetime as is\n",
    "    var_name=\"instrument\",  # Former column names become instrument names\n",
    "    value_name=\"label\"  # Values in the DataFrame become the label column\n",
    ")\n",
    "label_df_long = label_df_long.dropna(subset=[\"label\"])  # Drop NaN labels\n",
    "\n",
    "# Debugging: Check the reshaped DataFrame\n",
    "print(\"Reshaped label DataFrame:\")\n",
    "print(label_df_long.head())\n",
    "\n",
    "# Step 3: Combine with predictions\n",
    "# Ensure pred_df is in the long format with columns: datetime, instrument, prediction\n",
    "pred_label = pd.merge(label_df_long, pred_df, on=[\"datetime\", \"instrument\"], how=\"inner\")\n",
    "\n",
    "# Step 4: Rename the prediction column to 'score'\n",
    "pred_label = pred_label.rename(columns={0: \"score\"})\n",
    "\n",
    "# Drop rows with NaNs in the `label` or `score` columns\n",
    "pred_label = pred_label.dropna(subset=[\"label\", \"score\"])\n",
    "\n",
    "# Verify there are no NaNs remaining\n",
    "print(pred_label.isna().sum())\n",
    "\n",
    "# Convert `label` and `score` columns to numeric, coercing errors to NaN\n",
    "pred_label[\"label\"] = pd.to_numeric(pred_label[\"label\"], errors=\"coerce\")\n",
    "pred_label[\"score\"] = pd.to_numeric(pred_label[\"score\"], errors=\"coerce\")\n",
    "\n",
    "# Step 5: Set datetime and instrument as a multi-level index\n",
    "pred_label = pred_label.set_index([\"datetime\", \"instrument\"])  # Set the multi-level index\n",
    "\n",
    "# Verify the final structure\n",
    "\n",
    "figs = analysis_position.score_ic_graph(pred_label, show_notebook=False)\n",
    "for i, _fig in enumerate(figs):\n",
    "    fig_path = f\"{save_dir}/IC图表{i}.png\"\n",
    "    try:\n",
    "        _fig.write_image(fig_path)\n",
    "        print(f\"Saved figure {i} to {fig_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving figure {i}: {e}\")\n",
    "\n",
    "figs = analysis_model.model_performance_graph(pred_label, show_notebook=False)\n",
    "for i, _fig in enumerate(figs):\n",
    "    fig_path = f\"{save_dir}/模型性能图表{i}.png\"\n",
    "    try:\n",
    "        _fig.write_image(fig_path)\n",
    "        print(f\"Saved figure {i} to {fig_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving figures {i}: {e}\")\n",
    "\n",
    "\n",
    "print(f\"[Status]: Mission Completed\".upper())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MASTER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
