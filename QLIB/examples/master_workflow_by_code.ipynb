{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/qlib/blob/main/examples/workflow_by_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow of Qlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import sys\n",
    "import qlib\n",
    "from qlib.config import REG_CN\n",
    "from qlib.utils import init_instance_by_config\n",
    "from qlib.workflow import R\n",
    "from qlib.workflow.record_temp import SignalRecord, SigAnaRecord, PortAnaRecord\n",
    "from qlib.contrib.model.pytorch_master_ts import MASTERModel\n",
    "from qlib.contrib.data.dataset import MASTERTSDatasetH\n",
    "from qlib.contrib.data.handler import Alpha158"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Qlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-07 01:32:39.663\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mqlib.tests.data\u001b[0m:\u001b[36mqlib_data\u001b[0m:\u001b[36m195\u001b[0m - \u001b[33m\u001b[1mData already exists: ~/QuantProject/.qlib/qlib_data/cn_data, the data download will be skipped\n",
      "\tIf downloading is required: `exists_skip=False` or `change target_dir`\u001b[0m\n",
      "[94660:MainThread](2025-04-07 01:32:39,675) INFO - qlib.Initialization - [config.py:420] - default_conf: client.\n",
      "[94660:MainThread](2025-04-07 01:32:39,682) INFO - qlib.Initialization - [__init__.py:74] - qlib successfully initialized based on client settings.\n",
      "[94660:MainThread](2025-04-07 01:32:39,683) INFO - qlib.Initialization - [__init__.py:76] - data_path={'__DEFAULT_FREQ': PosixPath('/home/24039378g/QuantProject/.qlib/qlib_data/cn_data')}\n"
     ]
    }
   ],
   "source": [
    "from qlib.tests.data import GetData\n",
    "\n",
    "\n",
    "provider_uri = \"~/QuantProject/.qlib/qlib_data/cn_data\"\n",
    "GetData().qlib_data(target_dir=provider_uri, region=REG_CN, exists_skip=True)\n",
    "qlib.init(provider_uri=provider_uri, region=REG_CN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration of Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置参数\n",
    "market = \"csi300\"\n",
    "benchmark = \"SH000300\"\n",
    "\n",
    "# 数据处理器配置\n",
    "data_handler_config = {\n",
    "    \"start_time\": \"2008-01-01\",\n",
    "    \"end_time\": \"2020-08-01\",\n",
    "    \"fit_start_time\": \"2008-01-01\",\n",
    "    \"fit_end_time\": \"2014-12-31\",\n",
    "    \"instruments\": market,\n",
    "    \"infer_processors\": [\n",
    "        {\n",
    "            \"class\": \"RobustZScoreNorm\",\n",
    "            \"kwargs\": {\n",
    "                \"fields_group\": \"feature\",\n",
    "                \"clip_outlier\": True\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"class\": \"Fillna\",\n",
    "            \"kwargs\": {\n",
    "                \"fields_group\": \"feature\"\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"learn_processors\": [\n",
    "        {\"class\": \"DropnaLabel\"},\n",
    "        {\n",
    "            \"class\": \"CSRankNorm\",\n",
    "            \"kwargs\": {\n",
    "                \"fields_group\": \"label\"\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"label\": [\"Ref($close, -5) / Ref($close, -1) - 1\"]\n",
    "}\n",
    "\n",
    "market_data_handler_config = {\n",
    "    \"start_time\": \"2008-01-01\",\n",
    "    \"end_time\": \"2020-08-01\",\n",
    "    \"fit_start_time\": \"2008-01-01\",\n",
    "    \"fit_end_time\": \"2014-12-31\",\n",
    "    \"instruments\": market,\n",
    "    \"infer_processors\": [\n",
    "        {\n",
    "            \"class\": \"RobustZScoreNorm\",\n",
    "            \"kwargs\": {\n",
    "                \"fields_group\": \"feature\",\n",
    "                \"clip_outlier\": True\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"class\": \"Fillna\",\n",
    "            \"kwargs\": {\n",
    "                \"fields_group\": \"feature\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 模型配置\n",
    "model_config = {\n",
    "    \"class\": \"MASTERModel\",\n",
    "    \"module_path\": \"qlib.contrib.model.pytorch_master_ts\",\n",
    "    \"kwargs\": {\n",
    "        \"seed\": 0,\n",
    "        \"n_epochs\": 40,\n",
    "        \"lr\": 0.000008,\n",
    "        \"train_stop_loss_thred\": 0.95,\n",
    "        \"market\": market,\n",
    "        \"benchmark\": benchmark,\n",
    "        \"save_prefix\": market\n",
    "    }\n",
    "}\n",
    "\n",
    "# 数据集配置\n",
    "dataset_config = {\n",
    "    \"class\": \"MASTERTSDatasetH\",\n",
    "    \"module_path\": \"qlib.contrib.data.dataset\",\n",
    "    \"kwargs\": {\n",
    "        \"handler\": {\n",
    "            \"class\": \"Alpha158\",\n",
    "            \"module_path\": \"qlib.contrib.data.handler\",\n",
    "            \"kwargs\": data_handler_config\n",
    "        },\n",
    "        \"segments\": {\n",
    "            \"train\": [\"2008-01-01\", \"2014-12-31\"],\n",
    "            \"valid\": [\"2015-01-01\", \"2016-12-31\"],\n",
    "            \"test\": [\"2017-01-01\", \"2020-08-01\"]\n",
    "        },\n",
    "        \"step_len\": 8,\n",
    "        \"market_data_handler_config\": market_data_handler_config\n",
    "    }\n",
    "}\n",
    "\n",
    "# 投资组合分析配置\n",
    "port_analysis_config = {\n",
    "    \"strategy\": {\n",
    "        \"class\": \"TopkDropoutStrategy\",\n",
    "        \"module_path\": \"qlib.contrib.strategy\",\n",
    "        \"kwargs\": {\n",
    "            \"signal\": \"<PRED>\",\n",
    "            \"topk\": 30,\n",
    "            \"n_drop\": 30\n",
    "        }\n",
    "    },\n",
    "    \"backtest\": {\n",
    "        \"start_time\": \"2017-01-01\",\n",
    "        \"end_time\": \"2020-08-01\",\n",
    "        \"account\": 100000000,\n",
    "        \"benchmark\": benchmark,\n",
    "        \"exchange_kwargs\": {\n",
    "            \"deal_price\": \"close\"\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model and Dataset Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "模型参数量统计:\n",
      "--------------------------------------------------\n",
      "特征门控层 (Gate): 10,112 参数\n",
      "输入映射层 (x2y): 40,704 参数\n",
      "时间注意力层 (TAttention): 329,216 参数\n",
      "空间注意力层 (SAttention): 329,216 参数\n",
      "时序注意力层 (TemporalAttention): 65,536 参数\n",
      "解码器 (Decoder): 257 参数\n",
      "--------------------------------------------------\n",
      "总参数量: 775,041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[94660:MainThread](2025-04-07 01:32:49,326) INFO - qlib.timer - [log.py:127] - Time cost: 8.429s | Loading data Done\n",
      "/home/24039378g/.conda/envs/MASTER/lib/python3.12/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n",
      "[94660:MainThread](2025-04-07 01:32:56,947) INFO - qlib.timer - [log.py:127] - Time cost: 6.526s | RobustZScoreNorm Done\n",
      "[94660:MainThread](2025-04-07 01:32:58,059) INFO - qlib.timer - [log.py:127] - Time cost: 1.109s | Fillna Done\n",
      "[94660:MainThread](2025-04-07 01:32:58,836) INFO - qlib.timer - [log.py:127] - Time cost: 0.384s | DropnaLabel Done\n",
      "/home/24039378g/QuantProject/QLIB/qlib/data/dataset/processor.py:370: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[cols] = t\n",
      "[94660:MainThread](2025-04-07 01:32:59,082) INFO - qlib.timer - [log.py:127] - Time cost: 0.245s | CSRankNorm Done\n",
      "[94660:MainThread](2025-04-07 01:32:59,085) INFO - qlib.timer - [log.py:127] - Time cost: 9.757s | fit & process data Done\n",
      "[94660:MainThread](2025-04-07 01:32:59,086) INFO - qlib.timer - [log.py:127] - Time cost: 18.190s | Init data Done\n",
      "[94660:MainThread](2025-04-07 01:33:02,995) INFO - qlib.timer - [log.py:127] - Time cost: 3.872s | Loading data Done\n",
      "[94660:MainThread](2025-04-07 01:33:05,096) INFO - qlib.timer - [log.py:127] - Time cost: 1.960s | RobustZScoreNorm Done\n",
      "[94660:MainThread](2025-04-07 01:33:05,434) INFO - qlib.timer - [log.py:127] - Time cost: 0.336s | Fillna Done\n",
      "[94660:MainThread](2025-04-07 01:33:05,447) INFO - qlib.timer - [log.py:127] - Time cost: 2.450s | fit & process data Done\n",
      "[94660:MainThread](2025-04-07 01:33:05,448) INFO - qlib.timer - [log.py:127] - Time cost: 6.327s | Init data Done\n"
     ]
    }
   ],
   "source": [
    "model = init_instance_by_config(model_config)\n",
    "dataset = init_instance_by_config(dataset_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading or Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[94660:MainThread](2025-04-07 01:33:05,473) INFO - qlib.workflow - [exp.py:258] - Experiment 566184983307789232 starts running ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[94660:MainThread](2025-04-07 01:33:05,572) INFO - qlib.workflow - [recorder.py:345] - Recorder 0269be1064cf4a4fa54090142131cc23 starts running under Experiment 566184983307789232 ...\n",
      "[94660:MainThread](2025-04-07 01:33:05,756) INFO - qlib.timer - [log.py:127] - Time cost: 0.000s | waiting `async_log` Done\n"
     ]
    }
   ],
   "source": [
    "# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# model_name = f\"{market}{model_config[\"class\"]}_0\"\n",
    "model_name = f\"csi300master_0\"\n",
    "model_file_path = Path(f\"./model/{model_name}.pkl\")\n",
    "\n",
    "if not os.path.exists('./model'):\n",
    "    os.makedirs('./model')\n",
    "    \n",
    "with R.start(experiment_name=\"train_model\"):\n",
    "    if not model_file_path.exists():\n",
    "        R.log_params(**model_config[\"kwargs\"])\n",
    "        # print(\"文件列表:\", list(R.get_recorder().list_artifacts()))\n",
    "        \n",
    "        # 方法1：使用 sys.stdout.write\n",
    "        def custom_print(*args, **kwargs):\n",
    "            msg = ' '.join(map(str, args)) + '\\n'\n",
    "            import sys\n",
    "            sys.stdout.write(msg)\n",
    "        \n",
    "        # 临时替换 print\n",
    "        import builtins\n",
    "        orig_print = builtins.print\n",
    "        builtins.print = custom_print\n",
    "        \n",
    "        try:\n",
    "            model.fit(dataset)  # 训练模型\n",
    "        finally:\n",
    "            # pkl_path = os.path.join(\"./model\", f\"{model_name}.pkl\")\n",
    "            # with open(pkl_path, \"wb\") as f:\n",
    "            #     pickle.dump(model, f)\n",
    "            # 在master model里有一个生成函数\n",
    "            builtins.print = orig_print  # 确保恢复原始 print\n",
    "        \n",
    "        R.save_objects(trained_model=model)\n",
    "        \n",
    "    else:\n",
    "        model.load_model(f\"./model/{model_name}.pkl\")\n",
    "        R.save_objects(trained_model=model)\n",
    "        \n",
    "    rid = R.get_recorder().id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = {\n",
    "    k: []\n",
    "    for k in [\n",
    "        \"IC\",\n",
    "        \"ICIR\",\n",
    "        \"Rank IC\",\n",
    "        \"Rank ICIR\",\n",
    "        \"1day.excess_return_without_cost.annualized_return\",\n",
    "        \"1day.excess_return_without_cost.information_ratio\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[94660:MainThread](2025-04-07 01:33:05,788) INFO - qlib.workflow - [exp.py:258] - Experiment 362767161650010529 starts running ...\n",
      "[94660:MainThread](2025-04-07 01:33:05,822) INFO - qlib.workflow - [recorder.py:345] - Recorder 8e279bcb6138491da6ff8c768d6bd6cb starts running under Experiment 362767161650010529 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS]: MODEL TRAINING/ LOADING FINISHED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[94660:MainThread](2025-04-07 01:33:23,109) INFO - qlib.workflow - [record_temp.py:198] - Signal record 'pred.pkl' has been saved as the artifact of the Experiment 362767161650010529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'The following are prediction results of the MASTERModel model.'\n",
      "                              0\n",
      "datetime   instrument          \n",
      "2017-01-03 SH600000   -0.088509\n",
      "           SH600008    0.034699\n",
      "           SH600009    0.114184\n",
      "           SH600010   -0.067569\n",
      "           SH600015    0.010013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[94660:MainThread](2025-04-07 01:33:23,854) INFO - qlib.backtest caller - [__init__.py:93] - Create new exchange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'IC': 0.06221125738364682,\n",
      " 'ICIR': 0.4089395569850118,\n",
      " 'Rank IC': 0.07537232888943195,\n",
      " 'Rank ICIR': 0.500439035041941}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[94660:MainThread](2025-04-07 01:33:28,886) WARNING - qlib.online operator - [exchange.py:219] - $close field data contains nan.\n",
      "[94660:MainThread](2025-04-07 01:33:28,888) WARNING - qlib.online operator - [exchange.py:219] - $close field data contains nan.\n",
      "[94660:MainThread](2025-04-07 01:33:28,895) WARNING - qlib.online operator - [exchange.py:226] - factor.day.bin file not exists or factor contains `nan`. Order using adjusted_price.\n",
      "[94660:MainThread](2025-04-07 01:33:28,896) WARNING - qlib.online operator - [exchange.py:228] - trade unit 100 is not supported in adjusted_price mode.\n",
      "[94660:MainThread](2025-04-07 01:33:44,761) WARNING - qlib.data - [data.py:665] - load calendar error: freq=day, future=True; return current calendar!\n",
      "[94660:MainThread](2025-04-07 01:33:44,764) WARNING - qlib.data - [data.py:668] - You can get future calendar by referring to the following document: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/contrib/README.md\n",
      "[94660:MainThread](2025-04-07 01:33:44,983) WARNING - qlib.BaseExecutor - [executor.py:121] - `common_infra` is not set for <qlib.backtest.executor.SimulatorExecutor object at 0x15551fc93290>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19754109675e4fccb01e7699e6cb68ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "backtest loop:   0%|          | 0/871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/24039378g/QuantProject/QLIB/qlib/utils/index_data.py:492: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(self.data)\n",
      "/home/24039378g/QuantProject/QLIB/qlib/utils/index_data.py:492: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(self.data)\n",
      "/home/24039378g/QuantProject/QLIB/qlib/utils/index_data.py:492: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(self.data)\n",
      "[94660:MainThread](2025-04-07 01:33:57,492) INFO - qlib.workflow - [record_temp.py:515] - Portfolio analysis record 'port_analysis_1day.pkl' has been saved as the artifact of the Experiment 362767161650010529\n",
      "[94660:MainThread](2025-04-07 01:33:57,499) INFO - qlib.workflow - [record_temp.py:540] - Indicator analysis record 'indicator_analysis_1day.pkl' has been saved as the artifact of the Experiment 362767161650010529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'The following are analysis results of benchmark return(1day).'\n",
      "                       risk\n",
      "mean               0.000477\n",
      "std                0.012295\n",
      "annualized_return  0.113561\n",
      "information_ratio  0.598699\n",
      "max_drawdown      -0.370479\n",
      "'The following are analysis results of the excess return without cost(1day).'\n",
      "                       risk\n",
      "mean               0.000769\n",
      "std                0.006422\n",
      "annualized_return  0.182988\n",
      "information_ratio  1.846895\n",
      "max_drawdown      -0.077623\n",
      "'The following are analysis results of the excess return with cost(1day).'\n",
      "                       risk\n",
      "mean              -0.000647\n",
      "std                0.006410\n",
      "annualized_return -0.153964\n",
      "information_ratio -1.556917\n",
      "max_drawdown      -0.556260\n",
      "'The following are analysis results of indicators(1day).'\n",
      "     value\n",
      "ffr    1.0\n",
      "pa     0.0\n",
      "pos    0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[94660:MainThread](2025-04-07 01:33:58,777) INFO - qlib.timer - [log.py:127] - Time cost: 0.001s | waiting `async_log` Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: {'1day.ffr': 1.0, 'Rank ICIR': 0.500439035041941, '1day.excess_return_with_cost.information_ratio': -1.5569168277968284, '1day.excess_return_with_cost.annualized_return': -0.1539640160616905, '1day.excess_return_without_cost.information_ratio': 1.8468949496149516, '1day.pos': 0.0, 'IC': 0.06221125738364682, 'ICIR': 0.4089395569850118, '1day.pa': 0.0, '1day.excess_return_without_cost.std': 0.006422333820235034, 'Rank IC': 0.07537232888943195, '1day.excess_return_with_cost.mean': -0.0006469076305113046, '1day.excess_return_without_cost.mean': 0.0007688588023103395, '1day.excess_return_with_cost.max_drawdown': -0.5562598572484698, '1day.excess_return_without_cost.max_drawdown': -0.07762253352198856, '1day.excess_return_with_cost.std': 0.006410107895452495, '1day.excess_return_without_cost.annualized_return': 0.1829883949498608}\n",
      "All metrics: {'IC': [0.06221125738364682], 'ICIR': [0.4089395569850118], 'Rank IC': [0.07537232888943195], 'Rank ICIR': [0.500439035041941], '1day.excess_return_without_cost.annualized_return': [0.1829883949498608], '1day.excess_return_without_cost.information_ratio': [1.8468949496149516]}\n",
      "Available metrics: dict_keys(['1day.ffr', 'Rank ICIR', '1day.excess_return_with_cost.information_ratio', '1day.excess_return_with_cost.annualized_return', '1day.excess_return_without_cost.information_ratio', '1day.pos', 'IC', 'ICIR', '1day.pa', '1day.excess_return_without_cost.std', 'Rank IC', '1day.excess_return_with_cost.mean', '1day.excess_return_without_cost.mean', '1day.excess_return_with_cost.max_drawdown', '1day.excess_return_without_cost.max_drawdown', '1day.excess_return_with_cost.std', '1day.excess_return_without_cost.annualized_return'])\n",
      "IC: 0.06221125738364682 +- 0.0\n",
      "ICIR: 0.4089395569850118 +- 0.0\n",
      "Rank IC: 0.07537232888943195 +- 0.0\n",
      "Rank ICIR: 0.500439035041941 +- 0.0\n",
      "1day.excess_return_without_cost.annualized_return: 0.1829883949498608 +- 0.0\n",
      "1day.excess_return_without_cost.information_ratio: 1.8468949496149516 +- 0.0\n"
     ]
    }
   ],
   "source": [
    "# backtest and analysis\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "print(f\"[Status]: Model Training/ Loading finished\".upper())\n",
    "with R.start(experiment_name=\"backtest_analysis\"):\n",
    "    recorder = R.get_recorder(recorder_id=rid, experiment_name=\"train_model\")\n",
    "    model = recorder.load_object(\"trained_model\")\n",
    "\n",
    "    # prediction\n",
    "    recorder = R.get_recorder()\n",
    "    ba_rid = recorder.id\n",
    "    sr = SignalRecord(model, dataset, recorder)\n",
    "    sr.generate()\n",
    "    \n",
    "    # Signal Analysis\n",
    "    sar = SigAnaRecord(recorder)\n",
    "    sar.generate()\n",
    "\n",
    "    # backtest & analysis\n",
    "    par = PortAnaRecord(recorder, port_analysis_config, \"day\")\n",
    "    par.generate()\n",
    "    \n",
    "    metrics = recorder.list_metrics()\n",
    "    print(f\"Metrics: {metrics}\")\n",
    "    for k in all_metrics.keys():\n",
    "        all_metrics[k].append(metrics[k])\n",
    "    print(f\"All metrics: {all_metrics}\")\n",
    "    print(f\"Available metrics: {metrics.keys()}\")\n",
    "    \n",
    "for k in all_metrics.keys():\n",
    "        print(f\"{k}: {np.mean(all_metrics[k])} +- {np.std(all_metrics[k])}\")\n",
    "\n",
    "recorder = R.get_recorder(recorder_id=ba_rid, experiment_name=\"backtest_analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = recorder.load_object(\"pred.pkl\")\n",
    "\n",
    "report_normal_df = recorder.load_object(\"portfolio_analysis/report_normal_1day.pkl\")\n",
    "\n",
    "positions = recorder.load_object(\"portfolio_analysis/positions_normal_1day.pkl\")\n",
    "\n",
    "analysis_df = recorder.load_object(\"portfolio_analysis/port_analysis_1day.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figure 0 to figure_results/报告图表0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/24039378g/QuantProject/QLIB/qlib/contrib/report/analysis_position/risk_analysis.py:102: FutureWarning:\n",
      "\n",
      "When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "\n",
      "/home/24039378g/QuantProject/QLIB/qlib/contrib/report/analysis_position/risk_analysis.py:102: FutureWarning:\n",
      "\n",
      "When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "\n",
      "/home/24039378g/QuantProject/QLIB/qlib/contrib/report/analysis_position/risk_analysis.py:102: FutureWarning:\n",
      "\n",
      "When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "\n",
      "/home/24039378g/QuantProject/QLIB/qlib/contrib/report/analysis_position/risk_analysis.py:102: FutureWarning:\n",
      "\n",
      "When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figure 0 to figure_results/风险分析图表0.png\n",
      "Saved figure 1 to figure_results/风险分析图表1.png\n",
      "Saved figure 2 to figure_results/风险分析图表2.png\n",
      "Saved figure 3 to figure_results/风险分析图表3.png\n",
      "Saved figure 4 to figure_results/风险分析图表4.png\n",
      "Reshaped label DataFrame:\n",
      "    datetime instrument label\n",
      "0 2016-12-21   SH600000     0\n",
      "1 2016-12-22   SH600000   300\n",
      "2 2016-12-23   SH600000   600\n",
      "3 2016-12-26   SH600000   900\n",
      "4 2016-12-27   SH600000  1200\n",
      "datetime      0\n",
      "instrument    0\n",
      "label         0\n",
      "score         0\n",
      "dtype: int64\n",
      "Saved figure 0 to figure_results/IC图表0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/24039378g/QuantProject/QLIB/qlib/contrib/report/analysis_model/analysis_model_performance.py:155: FutureWarning:\n",
      "\n",
      "'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figure 0 to figure_results/模型性能图表0.png\n",
      "Saved figure 1 to figure_results/模型性能图表1.png\n",
      "Saved figure 2 to figure_results/模型性能图表2.png\n",
      "Saved figure 3 to figure_results/模型性能图表3.png\n",
      "Saved figure 4 to figure_results/模型性能图表4.png\n",
      "Saved figure 5 to figure_results/模型性能图表5.png\n",
      "[STATUS]: MISSION COMPLETED\n"
     ]
    }
   ],
   "source": [
    "from qlib.contrib.report import analysis_model, analysis_position\n",
    "import pandas as pd\n",
    "\n",
    "save_dir = \"figure_results\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "figs = analysis_position.report_graph(report_normal_df, show_notebook=False)\n",
    "if not figs:\n",
    "    raise ValueError(\"No figures were generated by `report_graph`. Please check the input data.\")\n",
    "\n",
    "for i, _fig in enumerate(figs):\n",
    "    fig_path = f\"{save_dir}/报告图表{i}.png\"\n",
    "    try:\n",
    "        _fig.write_image(fig_path)\n",
    "        print(f\"Saved figure {i} to {fig_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving figure {i}: {e}\")\n",
    "\n",
    "figs = analysis_position.risk_analysis_graph(analysis_df, report_normal_df, show_notebook=False)\n",
    "if not figs:\n",
    "    raise ValueError(\"No figures were generated by `risk_analysis_graph`. Please check the input data.\")\n",
    "\n",
    "for i, _fig in enumerate(figs):\n",
    "    fig_path = f\"{save_dir}/风险分析图表{i}.png\"\n",
    "    try:\n",
    "        _fig.write_image(fig_path)\n",
    "        print(f\"Saved figure {i} to {fig_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving figure {i}: {e}\")\n",
    "\n",
    "# Step 1: Retrieve TSDataSampler and extract the underlying DataFrame\n",
    "label_sampler = dataset.prepare(segments=\"test\", col_set=\"label\", only_label=True)\n",
    "label_df = label_sampler.idx_df  # Extract the DataFrame\n",
    "\n",
    "# Step 2: Reshape label_df to long format\n",
    "label_df = label_df.reset_index()  # Include datetime as a column\n",
    "label_df_long = pd.melt(\n",
    "    label_df,\n",
    "    id_vars=[\"datetime\"],  # Keep datetime as is\n",
    "    var_name=\"instrument\",  # Former column names become instrument names\n",
    "    value_name=\"label\"  # Values in the DataFrame become the label column\n",
    ")\n",
    "label_df_long = label_df_long.dropna(subset=[\"label\"])  # Drop NaN labels\n",
    "\n",
    "# Debugging: Check the reshaped DataFrame\n",
    "print(\"Reshaped label DataFrame:\")\n",
    "print(label_df_long.head())\n",
    "\n",
    "# Step 3: Combine with predictions\n",
    "# Ensure pred_df is in the long format with columns: datetime, instrument, prediction\n",
    "pred_label = pd.merge(label_df_long, pred_df, on=[\"datetime\", \"instrument\"], how=\"inner\")\n",
    "\n",
    "# Step 4: Rename the prediction column to 'score'\n",
    "pred_label = pred_label.rename(columns={0: \"score\"})\n",
    "\n",
    "# Drop rows with NaNs in the `label` or `score` columns\n",
    "pred_label = pred_label.dropna(subset=[\"label\", \"score\"])\n",
    "\n",
    "# Verify there are no NaNs remaining\n",
    "print(pred_label.isna().sum())\n",
    "\n",
    "# Convert `label` and `score` columns to numeric, coercing errors to NaN\n",
    "pred_label[\"label\"] = pd.to_numeric(pred_label[\"label\"], errors=\"coerce\")\n",
    "pred_label[\"score\"] = pd.to_numeric(pred_label[\"score\"], errors=\"coerce\")\n",
    "\n",
    "# Step 5: Set datetime and instrument as a multi-level index\n",
    "pred_label = pred_label.set_index([\"datetime\", \"instrument\"])  # Set the multi-level index\n",
    "\n",
    "# Verify the final structure\n",
    "\n",
    "figs = analysis_position.score_ic_graph(pred_label, show_notebook=False)\n",
    "for i, _fig in enumerate(figs):\n",
    "    fig_path = f\"{save_dir}/IC图表{i}.png\"\n",
    "    try:\n",
    "        _fig.write_image(fig_path)\n",
    "        print(f\"Saved figure {i} to {fig_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving figure {i}: {e}\")\n",
    "\n",
    "figs = analysis_model.model_performance_graph(pred_label, show_notebook=False)\n",
    "for i, _fig in enumerate(figs):\n",
    "    fig_path = f\"{save_dir}/模型性能图表{i}.png\"\n",
    "    try:\n",
    "        _fig.write_image(fig_path)\n",
    "        print(f\"Saved figure {i} to {fig_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving figures {i}: {e}\")\n",
    "\n",
    "\n",
    "print(f\"[Status]: Mission Completed\".upper())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MASTER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
