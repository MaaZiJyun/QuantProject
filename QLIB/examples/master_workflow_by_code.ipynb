{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/qlib/blob/main/examples/workflow_by_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow of Qlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import sys\n",
    "import qlib\n",
    "from qlib.config import REG_CN\n",
    "from qlib.utils import init_instance_by_config\n",
    "from qlib.workflow import R\n",
    "from qlib.workflow.record_temp import SignalRecord, SigAnaRecord, PortAnaRecord\n",
    "from qlib.contrib.model.pytorch_master_ts import MASTERModel\n",
    "from qlib.contrib.data.dataset import MASTERTSDatasetH\n",
    "from qlib.contrib.data.handler import Alpha158"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Qlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-07 00:12:20.218\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mqlib.tests.data\u001b[0m:\u001b[36mqlib_data\u001b[0m:\u001b[36m195\u001b[0m - \u001b[33m\u001b[1mData already exists: ~/QuantProject/.qlib/qlib_data/cn_data, the data download will be skipped\n",
      "\tIf downloading is required: `exists_skip=False` or `change target_dir`\u001b[0m\n",
      "[4170091:MainThread](2025-04-07 00:12:20,230) INFO - qlib.Initialization - [config.py:420] - default_conf: client.\n",
      "[4170091:MainThread](2025-04-07 00:12:20,237) INFO - qlib.Initialization - [__init__.py:74] - qlib successfully initialized based on client settings.\n",
      "[4170091:MainThread](2025-04-07 00:12:20,238) INFO - qlib.Initialization - [__init__.py:76] - data_path={'__DEFAULT_FREQ': PosixPath('/home/24039378g/QuantProject/.qlib/qlib_data/cn_data')}\n"
     ]
    }
   ],
   "source": [
    "from qlib.tests.data import GetData\n",
    "\n",
    "\n",
    "provider_uri = \"~/QuantProject/.qlib/qlib_data/cn_data\"\n",
    "GetData().qlib_data(target_dir=provider_uri, region=REG_CN, exists_skip=True)\n",
    "qlib.init(provider_uri=provider_uri, region=REG_CN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration of Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置参数\n",
    "market = \"csi300\"\n",
    "benchmark = \"SH000300\"\n",
    "\n",
    "# 数据处理器配置\n",
    "data_handler_config = {\n",
    "    \"start_time\": \"2008-01-01\",\n",
    "    \"end_time\": \"2020-08-01\",\n",
    "    \"fit_start_time\": \"2008-01-01\",\n",
    "    \"fit_end_time\": \"2014-12-31\",\n",
    "    \"instruments\": market,\n",
    "    \"infer_processors\": [\n",
    "        {\n",
    "            \"class\": \"RobustZScoreNorm\",\n",
    "            \"kwargs\": {\n",
    "                \"fields_group\": \"feature\",\n",
    "                \"clip_outlier\": True\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"class\": \"Fillna\",\n",
    "            \"kwargs\": {\n",
    "                \"fields_group\": \"feature\"\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"learn_processors\": [\n",
    "        {\"class\": \"DropnaLabel\"},\n",
    "        {\n",
    "            \"class\": \"CSRankNorm\",\n",
    "            \"kwargs\": {\n",
    "                \"fields_group\": \"label\"\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"label\": [\"Ref($close, -5) / Ref($close, -1) - 1\"]\n",
    "}\n",
    "\n",
    "market_data_handler_config = {\n",
    "    \"start_time\": \"2008-01-01\",\n",
    "    \"end_time\": \"2020-08-01\",\n",
    "    \"fit_start_time\": \"2008-01-01\",\n",
    "    \"fit_end_time\": \"2014-12-31\",\n",
    "    \"instruments\": market,\n",
    "    \"infer_processors\": [\n",
    "        {\n",
    "            \"class\": \"RobustZScoreNorm\",\n",
    "            \"kwargs\": {\n",
    "                \"fields_group\": \"feature\",\n",
    "                \"clip_outlier\": True\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"class\": \"Fillna\",\n",
    "            \"kwargs\": {\n",
    "                \"fields_group\": \"feature\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 模型配置\n",
    "model_config = {\n",
    "    \"class\": \"MASTERModel\",\n",
    "    \"module_path\": \"qlib.contrib.model.pytorch_master_ts\",\n",
    "    \"kwargs\": {\n",
    "        \"seed\": 0,\n",
    "        \"n_epochs\": 40,\n",
    "        \"lr\": 0.000008,\n",
    "        \"train_stop_loss_thred\": 0.95,\n",
    "        \"market\": market,\n",
    "        \"benchmark\": benchmark,\n",
    "        \"save_prefix\": market\n",
    "    }\n",
    "}\n",
    "\n",
    "# 数据集配置\n",
    "dataset_config = {\n",
    "    \"class\": \"MASTERTSDatasetH\",\n",
    "    \"module_path\": \"qlib.contrib.data.dataset\",\n",
    "    \"kwargs\": {\n",
    "        \"handler\": {\n",
    "            \"class\": \"Alpha158\",\n",
    "            \"module_path\": \"qlib.contrib.data.handler\",\n",
    "            \"kwargs\": data_handler_config\n",
    "        },\n",
    "        \"segments\": {\n",
    "            \"train\": [\"2008-01-01\", \"2014-12-31\"],\n",
    "            \"valid\": [\"2015-01-01\", \"2016-12-31\"],\n",
    "            \"test\": [\"2017-01-01\", \"2020-08-01\"]\n",
    "        },\n",
    "        \"step_len\": 8,\n",
    "        \"market_data_handler_config\": market_data_handler_config\n",
    "    }\n",
    "}\n",
    "\n",
    "# 投资组合分析配置\n",
    "port_analysis_config = {\n",
    "    \"strategy\": {\n",
    "        \"class\": \"TopkDropoutStrategy\",\n",
    "        \"module_path\": \"qlib.contrib.strategy\",\n",
    "        \"kwargs\": {\n",
    "            \"signal\": \"<PRED>\",\n",
    "            \"topk\": 30,\n",
    "            \"n_drop\": 30\n",
    "        }\n",
    "    },\n",
    "    \"backtest\": {\n",
    "        \"start_time\": \"2017-01-01\",\n",
    "        \"end_time\": \"2020-08-01\",\n",
    "        \"account\": 100000000,\n",
    "        \"benchmark\": benchmark,\n",
    "        \"exchange_kwargs\": {\n",
    "            \"deal_price\": \"close\"\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model and Dataset Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "模型参数量统计:\n",
      "--------------------------------------------------\n",
      "特征门控层 (Gate): 10,112 参数\n",
      "输入映射层 (x2y): 40,704 参数\n",
      "时间注意力层 (TAttention): 329,216 参数\n",
      "空间注意力层 (SAttention): 329,216 参数\n",
      "时序注意力层 (TemporalAttention): 65,536 参数\n",
      "解码器 (Decoder): 257 参数\n",
      "--------------------------------------------------\n",
      "总参数量: 775,041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[4170091:MainThread](2025-04-07 00:13:05,446) INFO - qlib.timer - [log.py:127] - Time cost: 9.475s | Loading data Done\n",
      "/home/24039378g/.conda/envs/MASTER/lib/python3.12/site-packages/numpy/lib/nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n",
      "[4170091:MainThread](2025-04-07 00:13:10,537) INFO - qlib.timer - [log.py:127] - Time cost: 4.603s | RobustZScoreNorm Done\n",
      "[4170091:MainThread](2025-04-07 00:13:11,153) INFO - qlib.timer - [log.py:127] - Time cost: 0.613s | Fillna Done\n",
      "[4170091:MainThread](2025-04-07 00:13:11,573) INFO - qlib.timer - [log.py:127] - Time cost: 0.221s | DropnaLabel Done\n",
      "/home/24039378g/QuantProject/QLIB/qlib/data/dataset/processor.py:370: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[cols] = t\n",
      "[4170091:MainThread](2025-04-07 00:13:11,810) INFO - qlib.timer - [log.py:127] - Time cost: 0.236s | CSRankNorm Done\n",
      "[4170091:MainThread](2025-04-07 00:13:11,813) INFO - qlib.timer - [log.py:127] - Time cost: 6.365s | fit & process data Done\n",
      "[4170091:MainThread](2025-04-07 00:13:11,814) INFO - qlib.timer - [log.py:127] - Time cost: 15.843s | Init data Done\n",
      "[4170091:MainThread](2025-04-07 00:13:16,518) INFO - qlib.timer - [log.py:127] - Time cost: 4.673s | Loading data Done\n",
      "[4170091:MainThread](2025-04-07 00:13:18,324) INFO - qlib.timer - [log.py:127] - Time cost: 1.662s | RobustZScoreNorm Done\n",
      "[4170091:MainThread](2025-04-07 00:13:18,498) INFO - qlib.timer - [log.py:127] - Time cost: 0.171s | Fillna Done\n",
      "[4170091:MainThread](2025-04-07 00:13:18,515) INFO - qlib.timer - [log.py:127] - Time cost: 1.994s | fit & process data Done\n",
      "[4170091:MainThread](2025-04-07 00:13:18,516) INFO - qlib.timer - [log.py:127] - Time cost: 6.671s | Init data Done\n"
     ]
    }
   ],
   "source": [
    "model = init_instance_by_config(model_config)\n",
    "dataset = init_instance_by_config(dataset_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading or Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[4170091:MainThread](2025-04-07 01:24:23,009) INFO - qlib.workflow - [exp.py:258] - Experiment 566184983307789232 starts running ...\n",
      "[4170091:MainThread](2025-04-07 01:24:23,066) INFO - qlib.workflow - [recorder.py:345] - Recorder 91b4f13b4d5f4cfeabada4dce6eb5ca5 starts running under Experiment 566184983307789232 ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     22\u001b[39m builtins.print = custom_print\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     27\u001b[39m     \u001b[38;5;66;03m# pkl_path = os.path.join(\"./model\", f\"{model_name}.pkl\")\u001b[39;00m\n\u001b[32m     28\u001b[39m     \u001b[38;5;66;03m# with open(pkl_path, \"wb\") as f:\u001b[39;00m\n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m#     pickle.dump(model, f)\u001b[39;00m\n\u001b[32m     30\u001b[39m     \u001b[38;5;66;03m# 在master model里有一个生成函数\u001b[39;00m\n\u001b[32m     31\u001b[39m     builtins.print = orig_print  \u001b[38;5;66;03m# 确保恢复原始 print\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/QuantProject/QLIB/qlib/contrib/model/pytorch_master_ts.py:716\u001b[39m, in \u001b[36mMASTERModel.fit\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m    713\u001b[39m \u001b[38;5;66;03m# 训练循环\u001b[39;00m\n\u001b[32m    714\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.n_epochs):\n\u001b[32m    715\u001b[39m     \u001b[38;5;66;03m# 训练一个epoch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m     train_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    717\u001b[39m     \u001b[38;5;66;03m# 验证一个epoch\u001b[39;00m\n\u001b[32m    718\u001b[39m     val_loss = \u001b[38;5;28mself\u001b[39m.test_epoch(valid_loader)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/QuantProject/QLIB/qlib/contrib/model/pytorch_master_ts.py:636\u001b[39m, in \u001b[36mMASTERModel.train_epoch\u001b[39m\u001b[34m(self, data_loader)\u001b[39m\n\u001b[32m    634\u001b[39m \u001b[38;5;66;03m# 反向传播和优化\u001b[39;00m\n\u001b[32m    635\u001b[39m \u001b[38;5;28mself\u001b[39m.train_optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m636\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[38;5;66;03m# 梯度裁剪，防止梯度爆炸\u001b[39;00m\n\u001b[32m    638\u001b[39m torch.nn.utils.clip_grad_value_(\u001b[38;5;28mself\u001b[39m.model.parameters(), \u001b[32m3.0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/MASTER/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/MASTER/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/MASTER/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# model_name = f\"{market}{model_config[\"class\"]}_0\"\n",
    "model_name = f\"csi300master_0\"\n",
    "model_file_path = Path(f\"./model/{model_name}.pkl\")\n",
    "\n",
    "if not os.path.exists('./model'):\n",
    "    os.makedirs('./model')\n",
    "    \n",
    "with R.start(experiment_name=\"train_model\"):\n",
    "    if not model_file_path.exists():\n",
    "        R.log_params(**model_config[\"kwargs\"])\n",
    "        # print(\"文件列表:\", list(R.get_recorder().list_artifacts()))\n",
    "        \n",
    "        # 方法1：使用 sys.stdout.write\n",
    "        def custom_print(*args, **kwargs):\n",
    "            msg = ' '.join(map(str, args)) + '\\n'\n",
    "            import sys\n",
    "            sys.stdout.write(msg)\n",
    "        \n",
    "        # 临时替换 print\n",
    "        import builtins\n",
    "        orig_print = builtins.print\n",
    "        builtins.print = custom_print\n",
    "        \n",
    "        try:\n",
    "            model.fit(dataset)  # 训练模型\n",
    "        finally:\n",
    "            # pkl_path = os.path.join(\"./model\", f\"{model_name}.pkl\")\n",
    "            # with open(pkl_path, \"wb\") as f:\n",
    "            #     pickle.dump(model, f)\n",
    "            # 在master model里有一个生成函数\n",
    "            builtins.print = orig_print  # 确保恢复原始 print\n",
    "        \n",
    "        R.save_objects(trained_model=model)\n",
    "        \n",
    "    else:\n",
    "        model.load_model(f\"./model/{model_name}.pkl\")\n",
    "        R.save_objects(trained_model=model)\n",
    "        \n",
    "    rid = R.get_recorder().id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = {\n",
    "    k: []\n",
    "    for k in [\n",
    "        \"IC\",\n",
    "        \"ICIR\",\n",
    "        \"Rank IC\",\n",
    "        \"Rank ICIR\",\n",
    "        \"1day.excess_return_without_cost.annualized_return\",\n",
    "        \"1day.excess_return_without_cost.information_ratio\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3908378:MainThread](2025-04-06 22:25:07,912) INFO - qlib.workflow - [exp.py:258] - Experiment 362767161650010529 starts running ...\n",
      "[3908378:MainThread](2025-04-06 22:25:07,977) INFO - qlib.workflow - [recorder.py:345] - Recorder 8d84fab322dd47c782da32d0322d5857 starts running under Experiment 362767161650010529 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS]: MODEL TRAINING/ LOADING FINISHED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3908378:MainThread](2025-04-06 22:25:23,084) INFO - qlib.workflow - [record_temp.py:198] - Signal record 'pred.pkl' has been saved as the artifact of the Experiment 362767161650010529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'The following are prediction results of the MASTERModel model.'\n",
      "                              0\n",
      "datetime   instrument          \n",
      "2017-01-03 SH600000   -0.094200\n",
      "           SH600008    0.099505\n",
      "           SH600009    0.298842\n",
      "           SH600010   -0.023810\n",
      "           SH600015    0.067495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3908378:MainThread](2025-04-06 22:25:23,819) INFO - qlib.backtest caller - [__init__.py:93] - Create new exchange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'IC': 0.03648069232457443,\n",
      " 'ICIR': 0.2675256965377252,\n",
      " 'Rank IC': 0.04273447517543348,\n",
      " 'Rank ICIR': 0.29957152985370383}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3908378:MainThread](2025-04-06 22:25:29,059) WARNING - qlib.online operator - [exchange.py:219] - $close field data contains nan.\n",
      "[3908378:MainThread](2025-04-06 22:25:29,062) WARNING - qlib.online operator - [exchange.py:219] - $close field data contains nan.\n",
      "[3908378:MainThread](2025-04-06 22:25:29,069) WARNING - qlib.online operator - [exchange.py:226] - factor.day.bin file not exists or factor contains `nan`. Order using adjusted_price.\n",
      "[3908378:MainThread](2025-04-06 22:25:29,070) WARNING - qlib.online operator - [exchange.py:228] - trade unit 100 is not supported in adjusted_price mode.\n",
      "[3908378:MainThread](2025-04-06 22:25:44,801) WARNING - qlib.BaseExecutor - [executor.py:121] - `common_infra` is not set for <qlib.backtest.executor.SimulatorExecutor object at 0x1552fea3aea0>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533ff142c9b643d9a444b2869b81b477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "backtest loop:   0%|          | 0/871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/24039378g/QuantProject/QLIB/qlib/utils/index_data.py:492: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(self.data)\n",
      "/home/24039378g/QuantProject/QLIB/qlib/utils/index_data.py:492: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(self.data)\n",
      "/home/24039378g/QuantProject/QLIB/qlib/utils/index_data.py:492: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(self.data)\n",
      "[3908378:MainThread](2025-04-06 22:25:59,916) INFO - qlib.workflow - [record_temp.py:515] - Portfolio analysis record 'port_analysis_1day.pkl' has been saved as the artifact of the Experiment 362767161650010529\n",
      "[3908378:MainThread](2025-04-06 22:25:59,922) INFO - qlib.workflow - [record_temp.py:540] - Indicator analysis record 'indicator_analysis_1day.pkl' has been saved as the artifact of the Experiment 362767161650010529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'The following are analysis results of benchmark return(1day).'\n",
      "                       risk\n",
      "mean               0.000477\n",
      "std                0.012295\n",
      "annualized_return  0.113561\n",
      "information_ratio  0.598699\n",
      "max_drawdown      -0.370479\n",
      "'The following are analysis results of the excess return without cost(1day).'\n",
      "                       risk\n",
      "mean               0.000280\n",
      "std                0.005396\n",
      "annualized_return  0.066689\n",
      "information_ratio  0.801159\n",
      "max_drawdown      -0.119840\n",
      "'The following are analysis results of the excess return with cost(1day).'\n",
      "                       risk\n",
      "mean              -0.001737\n",
      "std                0.005399\n",
      "annualized_return -0.413358\n",
      "information_ratio -4.963131\n",
      "max_drawdown      -1.526544\n",
      "'The following are analysis results of indicators(1day).'\n",
      "     value\n",
      "ffr    1.0\n",
      "pa     0.0\n",
      "pos    0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3908378:MainThread](2025-04-06 22:26:02,053) INFO - qlib.timer - [log.py:127] - Time cost: 0.001s | waiting `async_log` Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: {'1day.ffr': 1.0, 'Rank ICIR': 0.29957152985370383, '1day.excess_return_with_cost.information_ratio': -4.963131106783359, '1day.excess_return_with_cost.annualized_return': -0.4133577531694415, '1day.excess_return_without_cost.information_ratio': 0.8011587221738969, '1day.pos': 0.0, 'IC': 0.03648069232457443, 'ICIR': 0.2675256965377252, '1day.pa': 0.0, '1day.excess_return_without_cost.std': 0.005395668816402809, 'Rank IC': 0.04273447517543348, '1day.excess_return_with_cost.mean': -0.001736797282224544, '1day.excess_return_without_cost.mean': 0.000280204671652662, '1day.excess_return_with_cost.max_drawdown': -1.5265442023044526, '1day.excess_return_without_cost.max_drawdown': -0.11983952371055057, '1day.excess_return_with_cost.std': 0.005398608841853511, '1day.excess_return_without_cost.annualized_return': 0.06668871185333357}\n",
      "All metrics: {'IC': [0.03648069232457443], 'ICIR': [0.2675256965377252], 'Rank IC': [0.04273447517543348], 'Rank ICIR': [0.29957152985370383], '1day.excess_return_without_cost.annualized_return': [0.06668871185333357], '1day.excess_return_without_cost.information_ratio': [0.8011587221738969]}\n",
      "Available metrics: dict_keys(['1day.ffr', 'Rank ICIR', '1day.excess_return_with_cost.information_ratio', '1day.excess_return_with_cost.annualized_return', '1day.excess_return_without_cost.information_ratio', '1day.pos', 'IC', 'ICIR', '1day.pa', '1day.excess_return_without_cost.std', 'Rank IC', '1day.excess_return_with_cost.mean', '1day.excess_return_without_cost.mean', '1day.excess_return_with_cost.max_drawdown', '1day.excess_return_without_cost.max_drawdown', '1day.excess_return_with_cost.std', '1day.excess_return_without_cost.annualized_return'])\n",
      "IC: 0.03648069232457443 +- 0.0\n",
      "ICIR: 0.2675256965377252 +- 0.0\n",
      "Rank IC: 0.04273447517543348 +- 0.0\n",
      "Rank ICIR: 0.29957152985370383 +- 0.0\n",
      "1day.excess_return_without_cost.annualized_return: 0.06668871185333357 +- 0.0\n",
      "1day.excess_return_without_cost.information_ratio: 0.8011587221738969 +- 0.0\n"
     ]
    }
   ],
   "source": [
    "# backtest and analysis\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "print(f\"[Status]: Model Training/ Loading finished\".upper())\n",
    "with R.start(experiment_name=\"backtest_analysis\"):\n",
    "    recorder = R.get_recorder(recorder_id=rid, experiment_name=\"train_model\")\n",
    "    model = recorder.load_object(\"trained_model\")\n",
    "\n",
    "    # prediction\n",
    "    recorder = R.get_recorder()\n",
    "    ba_rid = recorder.id\n",
    "    sr = SignalRecord(model, dataset, recorder)\n",
    "    sr.generate()\n",
    "    \n",
    "    # Signal Analysis\n",
    "    sar = SigAnaRecord(recorder)\n",
    "    sar.generate()\n",
    "\n",
    "    # backtest & analysis\n",
    "    par = PortAnaRecord(recorder, port_analysis_config, \"day\")\n",
    "    par.generate()\n",
    "    \n",
    "    metrics = recorder.list_metrics()\n",
    "    print(f\"Metrics: {metrics}\")\n",
    "    for k in all_metrics.keys():\n",
    "        all_metrics[k].append(metrics[k])\n",
    "    print(f\"All metrics: {all_metrics}\")\n",
    "    print(f\"Available metrics: {metrics.keys()}\")\n",
    "    \n",
    "for k in all_metrics.keys():\n",
    "        print(f\"{k}: {np.mean(all_metrics[k])} +- {np.std(all_metrics[k])}\")\n",
    "\n",
    "recorder = R.get_recorder(recorder_id=ba_rid, experiment_name=\"backtest_analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = recorder.load_object(\"pred.pkl\")\n",
    "\n",
    "report_normal_df = recorder.load_object(\"portfolio_analysis/report_normal_1day.pkl\")\n",
    "\n",
    "positions = recorder.load_object(\"portfolio_analysis/positions_normal_1day.pkl\")\n",
    "\n",
    "analysis_df = recorder.load_object(\"portfolio_analysis/port_analysis_1day.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figure 0 to figure_results/报告图表0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/24039378g/QuantProject/QLIB/qlib/contrib/report/analysis_position/risk_analysis.py:102: FutureWarning:\n",
      "\n",
      "When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "\n",
      "/home/24039378g/QuantProject/QLIB/qlib/contrib/report/analysis_position/risk_analysis.py:102: FutureWarning:\n",
      "\n",
      "When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "\n",
      "/home/24039378g/QuantProject/QLIB/qlib/contrib/report/analysis_position/risk_analysis.py:102: FutureWarning:\n",
      "\n",
      "When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "\n",
      "/home/24039378g/QuantProject/QLIB/qlib/contrib/report/analysis_position/risk_analysis.py:102: FutureWarning:\n",
      "\n",
      "When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figure 0 to figure_results/风险分析图表0.png\n",
      "Saved figure 1 to figure_results/风险分析图表1.png\n",
      "Saved figure 2 to figure_results/风险分析图表2.png\n",
      "Saved figure 3 to figure_results/风险分析图表3.png\n",
      "Saved figure 4 to figure_results/风险分析图表4.png\n",
      "Reshaped label DataFrame:\n",
      "    datetime instrument label\n",
      "0 2016-12-21   SH600000     0\n",
      "1 2016-12-22   SH600000   300\n",
      "2 2016-12-23   SH600000   600\n",
      "3 2016-12-26   SH600000   900\n",
      "4 2016-12-27   SH600000  1200\n",
      "datetime      0\n",
      "instrument    0\n",
      "label         0\n",
      "score         0\n",
      "dtype: int64\n",
      "Saved figure 0 to figure_results/IC图表0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/24039378g/QuantProject/QLIB/qlib/contrib/report/analysis_model/analysis_model_performance.py:155: FutureWarning:\n",
      "\n",
      "'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figure 0 to figure_results/模型性能图表0.png\n",
      "Saved figure 1 to figure_results/模型性能图表1.png\n",
      "Saved figure 2 to figure_results/模型性能图表2.png\n",
      "Saved figure 3 to figure_results/模型性能图表3.png\n",
      "Saved figure 4 to figure_results/模型性能图表4.png\n",
      "Saved figure 5 to figure_results/模型性能图表5.png\n",
      "[STATUS]: MISSION COMPLETED\n"
     ]
    }
   ],
   "source": [
    "from qlib.contrib.report import analysis_model, analysis_position\n",
    "import pandas as pd\n",
    "\n",
    "save_dir = \"figure_results\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "figs = analysis_position.report_graph(report_normal_df, show_notebook=False)\n",
    "if not figs:\n",
    "    raise ValueError(\"No figures were generated by `report_graph`. Please check the input data.\")\n",
    "\n",
    "for i, _fig in enumerate(figs):\n",
    "    fig_path = f\"{save_dir}/报告图表{i}.png\"\n",
    "    try:\n",
    "        _fig.write_image(fig_path)\n",
    "        print(f\"Saved figure {i} to {fig_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving figure {i}: {e}\")\n",
    "\n",
    "figs = analysis_position.risk_analysis_graph(analysis_df, report_normal_df, show_notebook=False)\n",
    "if not figs:\n",
    "    raise ValueError(\"No figures were generated by `risk_analysis_graph`. Please check the input data.\")\n",
    "\n",
    "for i, _fig in enumerate(figs):\n",
    "    fig_path = f\"{save_dir}/风险分析图表{i}.png\"\n",
    "    try:\n",
    "        _fig.write_image(fig_path)\n",
    "        print(f\"Saved figure {i} to {fig_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving figure {i}: {e}\")\n",
    "\n",
    "# Step 1: Retrieve TSDataSampler and extract the underlying DataFrame\n",
    "label_sampler = dataset.prepare(segments=\"test\", col_set=\"label\", only_label=True)\n",
    "label_df = label_sampler.idx_df  # Extract the DataFrame\n",
    "\n",
    "# Step 2: Reshape label_df to long format\n",
    "label_df = label_df.reset_index()  # Include datetime as a column\n",
    "label_df_long = pd.melt(\n",
    "    label_df,\n",
    "    id_vars=[\"datetime\"],  # Keep datetime as is\n",
    "    var_name=\"instrument\",  # Former column names become instrument names\n",
    "    value_name=\"label\"  # Values in the DataFrame become the label column\n",
    ")\n",
    "label_df_long = label_df_long.dropna(subset=[\"label\"])  # Drop NaN labels\n",
    "\n",
    "# Debugging: Check the reshaped DataFrame\n",
    "print(\"Reshaped label DataFrame:\")\n",
    "print(label_df_long.head())\n",
    "\n",
    "# Step 3: Combine with predictions\n",
    "# Ensure pred_df is in the long format with columns: datetime, instrument, prediction\n",
    "pred_label = pd.merge(label_df_long, pred_df, on=[\"datetime\", \"instrument\"], how=\"inner\")\n",
    "\n",
    "# Step 4: Rename the prediction column to 'score'\n",
    "pred_label = pred_label.rename(columns={0: \"score\"})\n",
    "\n",
    "# Drop rows with NaNs in the `label` or `score` columns\n",
    "pred_label = pred_label.dropna(subset=[\"label\", \"score\"])\n",
    "\n",
    "# Verify there are no NaNs remaining\n",
    "print(pred_label.isna().sum())\n",
    "\n",
    "# Convert `label` and `score` columns to numeric, coercing errors to NaN\n",
    "pred_label[\"label\"] = pd.to_numeric(pred_label[\"label\"], errors=\"coerce\")\n",
    "pred_label[\"score\"] = pd.to_numeric(pred_label[\"score\"], errors=\"coerce\")\n",
    "\n",
    "# Step 5: Set datetime and instrument as a multi-level index\n",
    "pred_label = pred_label.set_index([\"datetime\", \"instrument\"])  # Set the multi-level index\n",
    "\n",
    "# Verify the final structure\n",
    "\n",
    "figs = analysis_position.score_ic_graph(pred_label, show_notebook=False)\n",
    "for i, _fig in enumerate(figs):\n",
    "    fig_path = f\"{save_dir}/IC图表{i}.png\"\n",
    "    try:\n",
    "        _fig.write_image(fig_path)\n",
    "        print(f\"Saved figure {i} to {fig_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving figure {i}: {e}\")\n",
    "\n",
    "figs = analysis_model.model_performance_graph(pred_label, show_notebook=False)\n",
    "for i, _fig in enumerate(figs):\n",
    "    fig_path = f\"{save_dir}/模型性能图表{i}.png\"\n",
    "    try:\n",
    "        _fig.write_image(fig_path)\n",
    "        print(f\"Saved figure {i} to {fig_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving figures {i}: {e}\")\n",
    "\n",
    "\n",
    "print(f\"[Status]: Mission Completed\".upper())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MASTER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
